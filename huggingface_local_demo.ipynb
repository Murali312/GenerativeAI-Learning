{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247b87f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: transformers in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: torch in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-huggingface) (0.3.80)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-huggingface) (0.36.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.49)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.12.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.2)\n",
      "Requirement already satisfied: filelock in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.12.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\gen_ai_projects_l2\\openai\\venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain-huggingface transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6747ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11426c69",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m llm = \u001b[43mHuggingFacePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_model_id\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTinyLlama/TinyLlama-1.1B-Chat-v1.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.03\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\langchain_huggingface\\llms\\huggingface_pipeline.py:209\u001b[39m, in \u001b[36mHuggingFacePipeline.from_model_id\u001b[39m\u001b[34m(cls, model_id, task, backend, device, device_map, model_kwargs, pipeline_kwargs, batch_size, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m     model_cls = (\n\u001b[32m    204\u001b[39m         AutoModelForCausalLM\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m task == \u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m AutoModelForSeq2SeqLM\n\u001b[32m    207\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m model = \u001b[43mmodel_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model.config.pad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5048\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5038\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5039\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5041\u001b[39m     (\n\u001b[32m   5042\u001b[39m         model,\n\u001b[32m   5043\u001b[39m         missing_keys,\n\u001b[32m   5044\u001b[39m         unexpected_keys,\n\u001b[32m   5045\u001b[39m         mismatched_keys,\n\u001b[32m   5046\u001b[39m         offload_index,\n\u001b[32m   5047\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5048\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5054\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5059\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5063\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5064\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5065\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5468\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5465\u001b[39m         args_list = logging.tqdm(args_list, desc=\u001b[33m\"\u001b[39m\u001b[33mLoading checkpoint shards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5467\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[32m-> \u001b[39m\u001b[32m5468\u001b[39m         _error_msgs, disk_offload_index = \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5469\u001b[39m         error_msgs += _error_msgs\n\u001b[32m   5471\u001b[39m \u001b[38;5;66;03m# Save offloaded index if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:843\u001b[39m, in \u001b[36mload_shard_file\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     disk_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GEN_AI_Projects_L2\\OpenAI\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:750\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, hf_quantizer, keep_in_fp32_regex, device_mesh)\u001b[39m\n\u001b[32m    748\u001b[39m param = param[...]\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     param = \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[32m    752\u001b[39m     param = param.contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "    ),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e08f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ffaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_model.invoke(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e0a4aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "What is the capital of India?</s>\n",
      "<|assistant|>\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
